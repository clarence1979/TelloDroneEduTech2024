{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 20B\n",
    "\n",
    "In the first lab, it will recognise plate numbers. Run and see the magic! This code will work on VS Code in either MS Windows or Raspberry Pi (Linux)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installers - Run only once BEFORE you start your program (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following are pre-requisites for the code. Run it only once in the Pi 400\n",
    "\n",
    "import platform\n",
    "import os\n",
    "\n",
    "# Detect the operating system\n",
    "current_platform = platform.system()\n",
    "print(current_platform)\n",
    "if current_platform == \"Windows\":\n",
    "    # Windows-specific commands\n",
    "    \n",
    "    os.system('pip install djitellopy opencv-python pytesseract pillow openai==0.28 opencv-python-headless langchain langchain_openai google-cloud-vision')\n",
    "    \n",
    "    print(\"Installation completed for Windows. Note: tesseract-ocr may require manual installation on Windows.\")\n",
    "elif current_platform == \"Linux\":  # Pi 400\n",
    "    # Pi-specific commands\n",
    "\n",
    "    os.system('sudo pip3 install opencv-python djitellopy pytesseract opencv-python opencv-python-headless openai openai==0.28 langchain langchain_openai google-cloud-vision --break-system-packages')\n",
    "    os.system('sudo apt-get install tesseract-ocr -y')         \n",
    "    os.system('sudo apt-get install libgtk2.0-dev pkg-config && sudo apt-get install libgtk-3-dev -y')  \n",
    "    \n",
    "    os.system('wget -P /home/pi/Desktop/Lab20 https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_russian_plate_number.xml')\n",
    "    print(\"Installation completed for Raspberry Pi.\")\n",
    "else:\n",
    "    print(\"Unsupported platform. Please ensure you are running this on Windows or Raspberry Pi.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1 - Number Plate Recognition System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The following code is the code for a number plate recognition system. If the tello drone is connected, it will activate the drone's camera. If not, then it will activate the usb camera attached to your computer. You can also upload a picture of a numberplate to be analysed. It uses the Russian numberplate XML which might result in inaccuracies. Run this code, then comment on the accuracy of the recognition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revision 3\n",
    "\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import pytesseract\n",
    "from djitellopy import Tello\n",
    "import platform\n",
    "import tempfile\n",
    "import requests\n",
    "\n",
    "# Set the path to Tesseract OCR and will work for both windows and Linux\n",
    "if platform.system() == \"Windows\":\n",
    "    # Set the path for Windows\n",
    "    pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'\n",
    "else:\n",
    "    # Set the path for Linux (Raspberry Pi typically uses the system-installed tesseract)\n",
    "    pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n",
    "\n",
    "\n",
    "\n",
    "def is_tello_connected():\n",
    "    \"\"\"\n",
    "    Check if the Tello drone is connected.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tello = Tello()\n",
    "        tello.connect()\n",
    "        tello.streamon()\n",
    "        return True, tello\n",
    "    except Exception as e:\n",
    "        print(f\"Tello connection failed: {e}\")\n",
    "        return False, None\n",
    "\n",
    "\n",
    "def run_tello_gui(tello):\n",
    "    \"\"\"\n",
    "    Runs the GUI for the Tello drone control and recognition.\n",
    "    \"\"\"\n",
    "    frame_read = tello.get_frame_read()\n",
    "\n",
    "    # Load the Haar cascade for number plate detection from the internet (instead of downloading the file)\n",
    "    # URL to the Haar cascade file\n",
    "    url = \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_russian_plate_number.xml\"\n",
    "    response = requests.get(url)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".xml\") as temp_file:\n",
    "        temp_file.write(response.content)\n",
    "        temp_file_path = temp_file.name\n",
    "\n",
    "# Load the cascade\n",
    "    plate_cascade = cv2.CascadeClassifier(temp_file_path)\n",
    "    #plate_cascade = cv2.CascadeClassifier('haarcascade_russian_plate_number.xml')\n",
    "\n",
    "    def takeoff():\n",
    "        tello.takeoff()\n",
    "        takeoff_button.config(state=DISABLED)\n",
    "        land_button.config(state=NORMAL)\n",
    "        up_button.config(state=NORMAL)\n",
    "        down_button.config(state=NORMAL)\n",
    "        left_button.config(state=NORMAL)\n",
    "        right_button.config(state=NORMAL)\n",
    "        capture_button.config(state=NORMAL)\n",
    "\n",
    "    def land():\n",
    "        tello.land()\n",
    "        takeoff_button.config(state=NORMAL)\n",
    "        land_button.config(state=DISABLED)\n",
    "        up_button.config(state=DISABLED)\n",
    "        down_button.config(state=DISABLED)\n",
    "        left_button.config(state=DISABLED)\n",
    "        right_button.config(state=DISABLED)\n",
    "        capture_button.config(state=NORMAL)\n",
    "\n",
    "    def up():\n",
    "        tello.move_up(100)\n",
    "\n",
    "    def down():\n",
    "        tello.move_down(100)\n",
    "\n",
    "    def left():\n",
    "        tello.move_left(100)\n",
    "\n",
    "    def right():\n",
    "        tello.move_right(100)\n",
    "\n",
    "    def capture_and_display():\n",
    "        # Capture frame from Tello stream\n",
    "        frame = frame_read.frame\n",
    "\n",
    "        if frame is not None and frame.size != 0:\n",
    "            # Convert to grayscale for detection\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "            # Detect number plates in the image\n",
    "            plates = plate_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=4, minSize=(30, 30))\n",
    "\n",
    "            recognized_text = \"\"\n",
    "\n",
    "            for (x, y, w, h) in plates:\n",
    "                # Draw a rectangle around each detected number plate on the frame\n",
    "                cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                # Extract the plate region for OCR\n",
    "                plate_region = frame[y:y + h, x:x + w]\n",
    "\n",
    "                # Use Tesseract to recognize text in the plate region\n",
    "                plate_text = pytesseract.image_to_string(plate_region, config='--psm 8')\n",
    "                recognized_text += plate_text.strip() + \"\\n\"  # Add each plate's text to output\n",
    "\n",
    "            # Display the detected text in the GUI\n",
    "            text_label.config(text=recognized_text)\n",
    "\n",
    "            # Convert the frame to RGB and resize for Tkinter\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            img_pil = Image.fromarray(frame_rgb)\n",
    "            img_pil = img_pil.resize((200, 150))\n",
    "\n",
    "            # Convert to PhotoImage for Tkinter\n",
    "            img_tk = ImageTk.PhotoImage(img_pil)\n",
    "\n",
    "            # Update the image on the GUI\n",
    "            display_label.config(image=img_tk)\n",
    "            display_label.image = img_tk  # Keep a reference to avoid garbage collection\n",
    "        else:\n",
    "            print(\"Failed to capture frame from the Tello stream.\")\n",
    "\n",
    "    # GUI setup for Tello\n",
    "    window = Tk()\n",
    "    window.geometry(\"500x400\")\n",
    "    window.title(\"Tello Drone - Number Plate Recognition\")\n",
    "\n",
    "    # Buttons\n",
    "    global takeoff_button, land_button, up_button, down_button, left_button, right_button, capture_button\n",
    "\n",
    "    takeoff_button = Button(window, text=\"Take Off\", command=takeoff, state=NORMAL)\n",
    "    takeoff_button.place(x=20, y=20, width=120, height=40)\n",
    "\n",
    "    land_button = Button(window, text=\"Land\", command=land, state=DISABLED)\n",
    "    land_button.place(x=160, y=20, width=120, height=40)\n",
    "\n",
    "    up_button = Button(window, text=\"Up\", command=up, state=DISABLED)\n",
    "    up_button.place(x=90, y=80, width=120, height=40)\n",
    "\n",
    "    down_button = Button(window, text=\"Down\", command=down, state=DISABLED)\n",
    "    down_button.place(x=90, y=140, width=120, height=40)\n",
    "\n",
    "    left_button = Button(window, text=\"Left\", command=left, state=DISABLED)\n",
    "    left_button.place(x=20, y=200, width=120, height=40)\n",
    "\n",
    "    right_button = Button(window, text=\"Right\", command=right, state=DISABLED)\n",
    "    right_button.place(x=160, y=200, width=120, height=40)\n",
    "\n",
    "    capture_button = Button(window, text=\"Capture\", command=capture_and_display, state=NORMAL)\n",
    "    capture_button.place(x=90, y=260, width=120, height=40)\n",
    "\n",
    "    # Image display label\n",
    "    display_label = Label(window)\n",
    "    display_label.place(x=320, y=20, width=150, height=150)\n",
    "\n",
    "    # Label to display recognized number plate text\n",
    "    text_label = Label(window, text=\"\", font=(\"Helvetica\", 10), fg=\"blue\", wraplength=150)\n",
    "    text_label.place(x=320, y=200)\n",
    "\n",
    "    window.mainloop()\n",
    "\n",
    "\n",
    "def run_camera_gui():\n",
    "    \"\"\"\n",
    "    Runs the fallback GUI for image-based recognition.\n",
    "    \"\"\"\n",
    "    def upload_and_extract():\n",
    "        try:\n",
    "            # Open file dialog to select image\n",
    "            file_path = filedialog.askopenfilename(filetypes=[(\"Image Files\", \"*.png;*.jpg;*.jpeg\")])\n",
    "            if not file_path:\n",
    "                result_label.config(text=\"No file selected.\")\n",
    "                return\n",
    "\n",
    "            # Open the image using PIL\n",
    "            image = Image.open(file_path)\n",
    "\n",
    "            # Use Tesseract to extract text\n",
    "            extracted_text = pytesseract.image_to_string(image, config=\"--psm 8\")  # PSM 8: Assume single word/block\n",
    "            result_label.config(text=f\"Extracted Number Plate: {extracted_text.strip()}\")\n",
    "        except Exception as e:\n",
    "            result_label.config(text=f\"Error: {e}\")\n",
    "\n",
    "    # GUI setup for image upload\n",
    "    window = Tk()\n",
    "    window.title(\"Fallback - Number Plate Recognition\")\n",
    "    window.geometry(\"400x200\")\n",
    "\n",
    "    instruction_label = Label(window, text=\"Click 'Upload Image' to select a picture of a car.\")\n",
    "    instruction_label.pack(pady=10)\n",
    "\n",
    "    upload_button = Button(window, text=\"Upload Image\", command=upload_and_extract)\n",
    "    upload_button.pack(pady=10)\n",
    "\n",
    "    result_label = Label(window, text=\"\", fg=\"blue\", wraplength=350)\n",
    "    result_label.pack(pady=10)\n",
    "\n",
    "    \n",
    "\n",
    "    window.mainloop()\n",
    "\n",
    "\n",
    "# Main Program Logic\n",
    "tello_connected, tello = is_tello_connected()\n",
    "if tello_connected:\n",
    "    run_tello_gui(tello)\n",
    "else:\n",
    "    print(\"Tello drone not detected. Running fallback mode.\")\n",
    "    run_camera_gui()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Describe what happens when you run the code above (try with USB camera attached, and without camera attached. When camera not present, connect to drone.). Comment also on the accuracy of the image detection. Is it good? Is it bad? How do you improve the detection accuracy? Write your answer in the space below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2 - Kernel killer - Only Use when Drone program is not responding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code will kill the kernel - causing it to reset. Use when drone program is not responding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This program will kill the Kernel causing it to reset. Use when necessary (such as between code executions - when the drone is not responding)\n",
    "def killall(): \n",
    "    import os\n",
    "    import platform\n",
    "    import subprocess\n",
    "    import sys\n",
    "\n",
    "    def reset_kernel():\n",
    "    \n",
    "        #Detect the operating system and reset the Jupyter Notebook kernel accordingly.\n",
    "    \n",
    "        os_name = platform.system()\n",
    "        print(f\"Detected OS: {os_name}\")\n",
    "\n",
    "        if os_name == \"Linux\":  # Assuming Raspberry Pi 400 runs a Linux-based OS\n",
    "            try:\n",
    "            # Run the kill command for Python processes in Linux\n",
    "                print(\"Resetting kernel for Pi 400 (Linux)...\")\n",
    "                result = subprocess.run(\"kill -9 $(ps -A | grep python | awk '{print $1}')\", shell=True, check=True)\n",
    "                print(\"Kernel reset successfully!\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"Failed to reset kernel on Pi 400: {e}\")\n",
    "        elif os_name == \"Windows\":\n",
    "            try:\n",
    "            # Use os._exit to exit the Python process on Windows\n",
    "                print(\"Resetting kernel for Windows...\")\n",
    "                os._exit(0)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to reset kernel on Windows: {e}\")\n",
    "        else:\n",
    "            print(\"Unsupported operating system.\")\n",
    "\n",
    "# Run the kernel reset function\n",
    "    reset_kernel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3 - Object detection using AI (OpenAI) and Tello Drone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The last code is on object detection using AI. This code can detect what the Drone sees and describe it. Run the program below with multiple objects, then comment on the accuracy of the AI in the space below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import cv2\n",
    "from PIL import Image, ImageTk\n",
    "import base64\n",
    "import requests\n",
    "import os\n",
    "from djitellopy import Tello\n",
    "\n",
    "\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "# Initialize Tello and connect\n",
    "tello = Tello()\n",
    "tello.connect()\n",
    "tello.streamon()\n",
    "frame_read = tello.get_frame_read()\n",
    "\n",
    "def takeoff():\n",
    "    print(\"Taking off\")\n",
    "    tello.takeoff()\n",
    "\n",
    "def land():\n",
    "    print(\"Landing\")\n",
    "    tello.land()\n",
    "\n",
    "def up():\n",
    "    print(\"Moving up\")\n",
    "    tello.move_up(100)\n",
    "\n",
    "def down():\n",
    "    print(\"Moving down\")\n",
    "    tello.move_down(100)\n",
    "\n",
    "def left():\n",
    "    print(\"Moving left\")\n",
    "    tello.move_left(100)\n",
    "\n",
    "def right():\n",
    "    print(\"Moving right\")\n",
    "    tello.move_right(100)\n",
    "\n",
    "def capture_and_save_image():\n",
    "    # Capture frame from Tello\n",
    "    frame = frame_read.frame\n",
    "    if frame is not None:\n",
    "        cv2.imwrite(\"picture.jpg\", frame)\n",
    "        print(\"Image saved as picture.jpg\")\n",
    "        recognize_image_with_openai(\"picture.jpg\")\n",
    "\n",
    "        # Convert the frame to RGB for display\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        img_pil = Image.fromarray(frame_rgb)\n",
    "\n",
    "        # Resize the image for display in the GUI\n",
    "        img_pil = img_pil.resize((400, 300))  # Resize as needed\n",
    "        img_tk = ImageTk.PhotoImage(img_pil)\n",
    "\n",
    "        display_label.config(image=img_tk)\n",
    "        display_label.image = img_tk  # Keep a reference to avoid garbage collection\n",
    "\n",
    "    else:\n",
    "        print(\"Failed to capture image\")\n",
    "\n",
    "def recognize_image_with_openai(image_path):\n",
    "    # Convert image to Base64\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        base64_image = base64.b64encode(image_file.read()).decode('utf-8')\n",
    "    \n",
    "    # Set up API request\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \n",
    "        \"Authorization\": f\"Bearer {api_key}\"\n",
    "    }\n",
    "    payload = {\n",
    "        \"model\": \"gpt-4o-mini\",  # Adjust model as required\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Describe the content of the image\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"max_tokens\": 300\n",
    "    }\n",
    "    \n",
    "    response = requests.post(\"https://api.openai.com/v1/chat/completions\", headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        description = response.json()['choices'][0]['message']['content']\n",
    "        print(\"Description:\", description)\n",
    "        text_label = Label(window, text=\"\", font=(\"Helvetica\", 10), fg=\"blue\", wraplength=400, justify=\"left\")\n",
    "        text_label.place(x=50, y=170)\n",
    "        text_label.config(text=description)\n",
    "    else:\n",
    "        print(\"Failed to get a response:\", response.json())\n",
    "\n",
    "# GUI setup\n",
    "window = Tk()\n",
    "window.geometry(\"500x350\")\n",
    "\n",
    "button1 = Button(window, text=\"Take Off\", command=takeoff)\n",
    "button1.place(x=120, y=20, width=120, height=25)\n",
    "\n",
    "button2 = Button(window, text=\"Land\", command=land)\n",
    "button2.place(x=120, y=80, width=120, height=25)\n",
    "\n",
    "button3 = Button(window, text=\"Up\", command=up)\n",
    "button3.place(x=120, y=0, width=120, height=25)\n",
    "\n",
    "button4 = Button(window, text=\"Down\", command=down)\n",
    "button4.place(x=120, y=100, width=120, height=25)\n",
    "\n",
    "button5 = Button(window, text=\"Left\", command=left)\n",
    "button5.place(x=75, y=50, width=120, height=25)\n",
    "\n",
    "button6 = Button(window, text=\"Right\", command=right)\n",
    "button6.place(x=150, y=50, width=120, height=25)\n",
    "\n",
    "capture_button = Button(window, text=\"Capture Photo\", command=capture_and_save_image)\n",
    "capture_button.place(x=120, y=150, width=120, height=25)\n",
    "\n",
    "text_label = Label(window, text=\"\", font=(\"Helvetica\", 10), fg=\"blue\")\n",
    "text_label.place(x=250, y=170)\n",
    "\n",
    "display_label = Label(window)\n",
    "display_label.pack(pady=10)\n",
    "\n",
    "window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
